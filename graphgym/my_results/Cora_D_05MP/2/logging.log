GraphGymModule(
  (model): GNN(
    (encoder): FeatureEncoder()
    (pre_mp): GeneralMultiLayer(
      (Layer_0): GeneralLayer(
        (layer): Linear(
          (model): Linear(1433, 256, bias=False)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
    (mp): DelayGNNStage(
      (W_k1_t0): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k1_t1): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k2_t1): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k1_t2): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k2_t2): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k3_t2): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k1_t3): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k2_t3): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k3_t3): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k4_t3): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k1_t4): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k2_t4): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k3_t4): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k4_t4): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
      (W_k5_t4): GeneralLayer(
        (layer): GCNConv(
          (model): GCNConv(256, 256)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
    (post_mp): GNNNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): Linear(
            (model): Linear(256, 7, bias=True)
          )
        )
      )
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 128
  edge_encoder: False
  edge_encoder_bn: True
  edge_encoder_name: Bond
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: PyG
  label_column: none
  label_table: none
  location: local
  name: Cora
  node_encoder: False
  node_encoder_bn: True
  node_encoder_name: Atom
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  split: [0.8, 0.2]
  split_mode: random
  task: node
  task_type: classification
  to_undirected: False
  transductive: True
  transform: none
  tu_simple: True
delay:
  max_k: 5
devices: None
gnn:
  act: prelu
  agg: add
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: True
  clear_feature: True
  dim_inner: 256
  dropout: 0.0
  head: node
  keep_edge: 0.5
  l2norm: True
  layer_type: my_gcnconv
  layers_mp: 5
  layers_post_mp: 1
  layers_pre_mp: 1
  msg_direction: single
  normalize_adj: False
  self_msg: concat
  skip_every: 1
  stage_type: delay_gnn
gpu_mem: False
mem:
  inplace: False
metric_agg: argmax
metric_best: auto
model:
  edge_decoding: dot
  graph_pooling: add
  loss_fun: cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: gnn
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.01
  lr_decay: 0.1
  max_epoch: 100
  momentum: 0.9
  optimizer: adam
  scheduler: cos
  steps: [30, 60, 90]
  weight_decay: 0.0005
out_dir: my_results/Cora_D_05MP
params: 1359895
print: both
round: 4
run_dir: my_results/Cora_D_05MP/2
seed: 3
share:
  dim_in: 1433
  dim_out: 7
  num_splits: 3
  num_tasks: 1
tensorboard_agg: True
tensorboard_each_run: True
train:
  auto_resume: False
  batch_size: 32
  ckpt_clean: True
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 20
  iter_per_epoch: 32
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
Num parameters: 1359895
val: {'epoch': 0, 'loss': 1.9525, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.3717, 'accuracy': 0.078}
val: {'epoch': 0, 'loss': 1.8947, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.365, 'accuracy': 0.2}
train: {'epoch': 0, 'eta': 46.7837, 'loss': 1.9506, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.4726, 'accuracy': 0.0857}
val: {'epoch': 1, 'loss': 1.7821, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.3644, 'accuracy': 0.584}
train: {'epoch': 1, 'eta': 46.0638, 'loss': 1.7886, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.4675, 'accuracy': 0.7857}
val: {'epoch': 2, 'loss': 1.7013, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.3649, 'accuracy': 0.658}
train: {'epoch': 2, 'eta': 45.4629, 'loss': 1.6486, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.466, 'accuracy': 0.8643}
val: {'epoch': 3, 'loss': 1.6414, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.3637, 'accuracy': 0.698}
train: {'epoch': 3, 'eta': 44.8647, 'loss': 1.5551, 'lr': 0.01, 'params': 1359895, 'time_iter': 0.4633, 'accuracy': 0.8714}
val: {'epoch': 4, 'loss': 1.5964, 'lr': 0.0099, 'params': 1359895, 'time_iter': 0.3631, 'accuracy': 0.722}
train: {'epoch': 4, 'eta': 44.3539, 'loss': 1.4653, 'lr': 0.0099, 'params': 1359895, 'time_iter': 0.4651, 'accuracy': 0.9214}
val: {'epoch': 5, 'loss': 1.5609, 'lr': 0.0099, 'params': 1359895, 'time_iter': 0.363, 'accuracy': 0.734}
train: {'epoch': 5, 'eta': 43.8641, 'loss': 1.3769, 'lr': 0.0099, 'params': 1359895, 'time_iter': 0.4654, 'accuracy': 0.9214}
val: {'epoch': 6, 'loss': 1.5361, 'lr': 0.0099, 'params': 1359895, 'time_iter': 0.3644, 'accuracy': 0.718}
train: {'epoch': 6, 'eta': 43.4109, 'loss': 1.288, 'lr': 0.0099, 'params': 1359895, 'time_iter': 0.4676, 'accuracy': 0.95}
val: {'epoch': 7, 'loss': 1.5164, 'lr': 0.0098, 'params': 1359895, 'time_iter': 0.3628, 'accuracy': 0.704}
train: {'epoch': 7, 'eta': 42.9352, 'loss': 1.1978, 'lr': 0.0098, 'params': 1359895, 'time_iter': 0.466, 'accuracy': 0.9929}
val: {'epoch': 8, 'loss': 1.4789, 'lr': 0.0098, 'params': 1359895, 'time_iter': 0.3634, 'accuracy': 0.694}
train: {'epoch': 8, 'eta': 42.4484, 'loss': 1.1095, 'lr': 0.0098, 'params': 1359895, 'time_iter': 0.4647, 'accuracy': 0.9929}
val: {'epoch': 9, 'loss': 1.44, 'lr': 0.0098, 'params': 1359895, 'time_iter': 0.3604, 'accuracy': 0.692}
train: {'epoch': 9, 'eta': 41.9537, 'loss': 1.0241, 'lr': 0.0098, 'params': 1359895, 'time_iter': 0.4633, 'accuracy': 0.9929}
val: {'epoch': 10, 'loss': 1.4426, 'lr': 0.0097, 'params': 1359895, 'time_iter': 0.3626, 'accuracy': 0.664}
train: {'epoch': 10, 'eta': 41.4813, 'loss': 0.9425, 'lr': 0.0097, 'params': 1359895, 'time_iter': 0.4654, 'accuracy': 0.9929}
val: {'epoch': 11, 'loss': 1.366, 'lr': 0.0096, 'params': 1359895, 'time_iter': 0.3633, 'accuracy': 0.706}
train: {'epoch': 11, 'eta': 41.0024, 'loss': 0.8704, 'lr': 0.0096, 'params': 1359895, 'time_iter': 0.4643, 'accuracy': 1.0}
val: {'epoch': 12, 'loss': 1.2999, 'lr': 0.0096, 'params': 1359895, 'time_iter': 0.3625, 'accuracy': 0.72}
train: {'epoch': 12, 'eta': 40.5339, 'loss': 0.8136, 'lr': 0.0096, 'params': 1359895, 'time_iter': 0.4656, 'accuracy': 1.0}
val: {'epoch': 13, 'loss': 1.2991, 'lr': 0.0095, 'params': 1359895, 'time_iter': 0.3648, 'accuracy': 0.686}
train: {'epoch': 13, 'eta': 40.0649, 'loss': 0.7423, 'lr': 0.0095, 'params': 1359895, 'time_iter': 0.4654, 'accuracy': 1.0}
val: {'epoch': 14, 'loss': 1.257, 'lr': 0.0095, 'params': 1359895, 'time_iter': 0.3631, 'accuracy': 0.69}
train: {'epoch': 14, 'eta': 39.6055, 'loss': 0.6815, 'lr': 0.0095, 'params': 1359895, 'time_iter': 0.467, 'accuracy': 1.0}
val: {'epoch': 15, 'loss': 1.1858, 'lr': 0.0094, 'params': 1359895, 'time_iter': 0.3633, 'accuracy': 0.712}
train: {'epoch': 15, 'eta': 39.1326, 'loss': 0.6153, 'lr': 0.0094, 'params': 1359895, 'time_iter': 0.4646, 'accuracy': 1.0}
val: {'epoch': 16, 'loss': 1.1516, 'lr': 0.0093, 'params': 1359895, 'time_iter': 0.3618, 'accuracy': 0.716}
train: {'epoch': 16, 'eta': 38.6529, 'loss': 0.5582, 'lr': 0.0093, 'params': 1359895, 'time_iter': 0.463, 'accuracy': 1.0}
val: {'epoch': 17, 'loss': 1.1385, 'lr': 0.0092, 'params': 1359895, 'time_iter': 0.3672, 'accuracy': 0.714}
train: {'epoch': 17, 'eta': 38.1879, 'loss': 0.5097, 'lr': 0.0092, 'params': 1359895, 'time_iter': 0.4659, 'accuracy': 1.0}
val: {'epoch': 18, 'loss': 1.1277, 'lr': 0.0091, 'params': 1359895, 'time_iter': 0.3692, 'accuracy': 0.704}
train: {'epoch': 18, 'eta': 37.7544, 'loss': 0.4625, 'lr': 0.0091, 'params': 1359895, 'time_iter': 0.4732, 'accuracy': 1.0}
val: {'epoch': 19, 'loss': 1.1086, 'lr': 0.009, 'params': 1359895, 'time_iter': 0.3628, 'accuracy': 0.696}
train: {'epoch': 19, 'eta': 37.2873, 'loss': 0.4211, 'lr': 0.009, 'params': 1359895, 'time_iter': 0.4659, 'accuracy': 1.0}
val: {'epoch': 20, 'loss': 1.084, 'lr': 0.009, 'params': 1359895, 'time_iter': 0.3618, 'accuracy': 0.688}
train: {'epoch': 20, 'eta': 36.8208, 'loss': 0.3837, 'lr': 0.009, 'params': 1359895, 'time_iter': 0.466, 'accuracy': 1.0}
val: {'epoch': 21, 'loss': 1.0607, 'lr': 0.0089, 'params': 1359895, 'time_iter': 0.3619, 'accuracy': 0.69}
train: {'epoch': 21, 'eta': 36.351, 'loss': 0.3497, 'lr': 0.0089, 'params': 1359895, 'time_iter': 0.465, 'accuracy': 1.0}
val: {'epoch': 22, 'loss': 1.0553, 'lr': 0.0088, 'params': 1359895, 'time_iter': 0.3631, 'accuracy': 0.694}
train: {'epoch': 22, 'eta': 35.8772, 'loss': 0.3197, 'lr': 0.0088, 'params': 1359895, 'time_iter': 0.4637, 'accuracy': 1.0}
val: {'epoch': 23, 'loss': 1.0353, 'lr': 0.0086, 'params': 1359895, 'time_iter': 0.3645, 'accuracy': 0.696}
train: {'epoch': 23, 'eta': 35.4029, 'loss': 0.2925, 'lr': 0.0086, 'params': 1359895, 'time_iter': 0.4633, 'accuracy': 1.0}
val: {'epoch': 24, 'loss': 1.0491, 'lr': 0.0085, 'params': 1359895, 'time_iter': 0.3611, 'accuracy': 0.69}
train: {'epoch': 24, 'eta': 34.9308, 'loss': 0.2685, 'lr': 0.0085, 'params': 1359895, 'time_iter': 0.4637, 'accuracy': 1.0}
val: {'epoch': 25, 'loss': 1.0006, 'lr': 0.0084, 'params': 1359895, 'time_iter': 0.3624, 'accuracy': 0.71}
train: {'epoch': 25, 'eta': 34.4589, 'loss': 0.2474, 'lr': 0.0084, 'params': 1359895, 'time_iter': 0.4636, 'accuracy': 1.0}
val: {'epoch': 26, 'loss': 1.1112, 'lr': 0.0083, 'params': 1359895, 'time_iter': 0.3631, 'accuracy': 0.666}
train: {'epoch': 26, 'eta': 33.989, 'loss': 0.2299, 'lr': 0.0083, 'params': 1359895, 'time_iter': 0.4641, 'accuracy': 1.0}
val: {'epoch': 27, 'loss': 1.0429, 'lr': 0.0082, 'params': 1359895, 'time_iter': 0.3615, 'accuracy': 0.666}
train: {'epoch': 27, 'eta': 33.5169, 'loss': 0.22, 'lr': 0.0082, 'params': 1359895, 'time_iter': 0.4631, 'accuracy': 1.0}
val: {'epoch': 28, 'loss': 0.9026, 'lr': 0.0081, 'params': 1359895, 'time_iter': 0.3622, 'accuracy': 0.744}
train: {'epoch': 28, 'eta': 33.047, 'loss': 0.2991, 'lr': 0.0081, 'params': 1359895, 'time_iter': 0.4638, 'accuracy': 0.9643}
val: {'epoch': 29, 'loss': 0.9221, 'lr': 0.0079, 'params': 1359895, 'time_iter': 0.3662, 'accuracy': 0.724}
train: {'epoch': 29, 'eta': 32.5836, 'loss': 0.2337, 'lr': 0.0079, 'params': 1359895, 'time_iter': 0.4663, 'accuracy': 0.9857}
val: {'epoch': 30, 'loss': 0.9139, 'lr': 0.0078, 'params': 1359895, 'time_iter': 0.3611, 'accuracy': 0.728}
train: {'epoch': 30, 'eta': 32.1176, 'loss': 0.2052, 'lr': 0.0078, 'params': 1359895, 'time_iter': 0.4652, 'accuracy': 0.9857}
val: {'epoch': 31, 'loss': 0.9757, 'lr': 0.0077, 'params': 1359895, 'time_iter': 0.3612, 'accuracy': 0.704}
train: {'epoch': 31, 'eta': 31.6475, 'loss': 0.1792, 'lr': 0.0077, 'params': 1359895, 'time_iter': 0.4633, 'accuracy': 1.0}
val: {'epoch': 32, 'loss': 1.0941, 'lr': 0.0075, 'params': 1359895, 'time_iter': 0.3607, 'accuracy': 0.662}
train: {'epoch': 32, 'eta': 31.1789, 'loss': 0.1697, 'lr': 0.0075, 'params': 1359895, 'time_iter': 0.4638, 'accuracy': 1.0}
val: {'epoch': 33, 'loss': 1.1932, 'lr': 0.0074, 'params': 1359895, 'time_iter': 0.362, 'accuracy': 0.616}
train: {'epoch': 33, 'eta': 30.7088, 'loss': 0.155, 'lr': 0.0074, 'params': 1359895, 'time_iter': 0.4629, 'accuracy': 1.0}
val: {'epoch': 34, 'loss': 1.247, 'lr': 0.0073, 'params': 1359895, 'time_iter': 0.3648, 'accuracy': 0.592}
train: {'epoch': 34, 'eta': 30.2478, 'loss': 0.1444, 'lr': 0.0073, 'params': 1359895, 'time_iter': 0.4676, 'accuracy': 1.0}
val: {'epoch': 35, 'loss': 1.2567, 'lr': 0.0071, 'params': 1359895, 'time_iter': 0.3614, 'accuracy': 0.582}
train: {'epoch': 35, 'eta': 29.7843, 'loss': 0.1361, 'lr': 0.0071, 'params': 1359895, 'time_iter': 0.4664, 'accuracy': 1.0}
val: {'epoch': 36, 'loss': 1.2355, 'lr': 0.007, 'params': 1359895, 'time_iter': 0.3657, 'accuracy': 0.596}
train: {'epoch': 36, 'eta': 29.3177, 'loss': 0.1284, 'lr': 0.007, 'params': 1359895, 'time_iter': 0.4646, 'accuracy': 1.0}
val: {'epoch': 37, 'loss': 1.2053, 'lr': 0.0068, 'params': 1359895, 'time_iter': 0.3613, 'accuracy': 0.606}
train: {'epoch': 37, 'eta': 28.853, 'loss': 0.1209, 'lr': 0.0068, 'params': 1359895, 'time_iter': 0.4658, 'accuracy': 1.0}
val: {'epoch': 38, 'loss': 1.1801, 'lr': 0.0067, 'params': 1359895, 'time_iter': 0.3611, 'accuracy': 0.616}
train: {'epoch': 38, 'eta': 28.3907, 'loss': 0.1147, 'lr': 0.0067, 'params': 1359895, 'time_iter': 0.4674, 'accuracy': 1.0}
val: {'epoch': 39, 'loss': 1.162, 'lr': 0.0065, 'params': 1359895, 'time_iter': 0.3641, 'accuracy': 0.63}
train: {'epoch': 39, 'eta': 27.934, 'loss': 0.1094, 'lr': 0.0065, 'params': 1359895, 'time_iter': 0.4712, 'accuracy': 1.0}
val: {'epoch': 40, 'loss': 1.1499, 'lr': 0.0064, 'params': 1359895, 'time_iter': 0.3631, 'accuracy': 0.638}
train: {'epoch': 40, 'eta': 27.4696, 'loss': 0.1045, 'lr': 0.0064, 'params': 1359895, 'time_iter': 0.4664, 'accuracy': 1.0}
val: {'epoch': 41, 'loss': 1.1459, 'lr': 0.0062, 'params': 1359895, 'time_iter': 0.3647, 'accuracy': 0.646}
train: {'epoch': 41, 'eta': 27.0089, 'loss': 0.1001, 'lr': 0.0062, 'params': 1359895, 'time_iter': 0.4691, 'accuracy': 1.0}
val: {'epoch': 42, 'loss': 1.1478, 'lr': 0.0061, 'params': 1359895, 'time_iter': 0.3636, 'accuracy': 0.646}
train: {'epoch': 42, 'eta': 26.5454, 'loss': 0.0961, 'lr': 0.0061, 'params': 1359895, 'time_iter': 0.4673, 'accuracy': 1.0}
val: {'epoch': 43, 'loss': 1.1487, 'lr': 0.0059, 'params': 1359895, 'time_iter': 0.366, 'accuracy': 0.654}
train: {'epoch': 43, 'eta': 26.0867, 'loss': 0.0925, 'lr': 0.0059, 'params': 1359895, 'time_iter': 0.4712, 'accuracy': 1.0}
val: {'epoch': 44, 'loss': 1.1449, 'lr': 0.0058, 'params': 1359895, 'time_iter': 0.3671, 'accuracy': 0.652}
train: {'epoch': 44, 'eta': 25.6229, 'loss': 0.0894, 'lr': 0.0058, 'params': 1359895, 'time_iter': 0.4674, 'accuracy': 1.0}
val: {'epoch': 45, 'loss': 1.138, 'lr': 0.0056, 'params': 1359895, 'time_iter': 0.3669, 'accuracy': 0.654}
train: {'epoch': 45, 'eta': 25.1593, 'loss': 0.0864, 'lr': 0.0056, 'params': 1359895, 'time_iter': 0.4678, 'accuracy': 1.0}
val: {'epoch': 46, 'loss': 1.1289, 'lr': 0.0055, 'params': 1359895, 'time_iter': 0.3622, 'accuracy': 0.654}
train: {'epoch': 46, 'eta': 24.6912, 'loss': 0.0838, 'lr': 0.0055, 'params': 1359895, 'time_iter': 0.464, 'accuracy': 1.0}
val: {'epoch': 47, 'loss': 1.1186, 'lr': 0.0053, 'params': 1359895, 'time_iter': 0.3611, 'accuracy': 0.66}
train: {'epoch': 47, 'eta': 24.2269, 'loss': 0.0814, 'lr': 0.0053, 'params': 1359895, 'time_iter': 0.4674, 'accuracy': 1.0}
val: {'epoch': 48, 'loss': 1.1084, 'lr': 0.0052, 'params': 1359895, 'time_iter': 0.361, 'accuracy': 0.666}
train: {'epoch': 48, 'eta': 23.7588, 'loss': 0.0792, 'lr': 0.0052, 'params': 1359895, 'time_iter': 0.4637, 'accuracy': 1.0}
val: {'epoch': 49, 'loss': 1.0986, 'lr': 0.005, 'params': 1359895, 'time_iter': 0.3618, 'accuracy': 0.674}
train: {'epoch': 49, 'eta': 23.2964, 'loss': 0.0772, 'lr': 0.005, 'params': 1359895, 'time_iter': 0.4693, 'accuracy': 1.0}
val: {'epoch': 50, 'loss': 1.0898, 'lr': 0.0048, 'params': 1359895, 'time_iter': 0.364, 'accuracy': 0.67}
train: {'epoch': 50, 'eta': 22.8311, 'loss': 0.0754, 'lr': 0.0048, 'params': 1359895, 'time_iter': 0.4666, 'accuracy': 1.0}
val: {'epoch': 51, 'loss': 1.0801, 'lr': 0.0047, 'params': 1359895, 'time_iter': 0.3609, 'accuracy': 0.678}
train: {'epoch': 51, 'eta': 22.3635, 'loss': 0.0737, 'lr': 0.0047, 'params': 1359895, 'time_iter': 0.4641, 'accuracy': 1.0}
val: {'epoch': 52, 'loss': 1.0722, 'lr': 0.0045, 'params': 1359895, 'time_iter': 0.3613, 'accuracy': 0.678}
train: {'epoch': 52, 'eta': 21.8968, 'loss': 0.0722, 'lr': 0.0045, 'params': 1359895, 'time_iter': 0.465, 'accuracy': 1.0}
val: {'epoch': 53, 'loss': 1.0665, 'lr': 0.0044, 'params': 1359895, 'time_iter': 0.3638, 'accuracy': 0.676}
train: {'epoch': 53, 'eta': 21.4295, 'loss': 0.0708, 'lr': 0.0044, 'params': 1359895, 'time_iter': 0.4643, 'accuracy': 1.0}
val: {'epoch': 54, 'loss': 1.0595, 'lr': 0.0042, 'params': 1359895, 'time_iter': 0.368, 'accuracy': 0.678}
train: {'epoch': 54, 'eta': 20.9631, 'loss': 0.0695, 'lr': 0.0042, 'params': 1359895, 'time_iter': 0.4651, 'accuracy': 1.0}
val: {'epoch': 55, 'loss': 1.0517, 'lr': 0.0041, 'params': 1359895, 'time_iter': 0.3677, 'accuracy': 0.684}
train: {'epoch': 55, 'eta': 20.4985, 'loss': 0.0683, 'lr': 0.0041, 'params': 1359895, 'time_iter': 0.4674, 'accuracy': 1.0}
val: {'epoch': 56, 'loss': 1.0437, 'lr': 0.0039, 'params': 1359895, 'time_iter': 0.3632, 'accuracy': 0.686}
train: {'epoch': 56, 'eta': 20.0319, 'loss': 0.0671, 'lr': 0.0039, 'params': 1359895, 'time_iter': 0.465, 'accuracy': 1.0}
val: {'epoch': 57, 'loss': 1.036, 'lr': 0.0038, 'params': 1359895, 'time_iter': 0.3614, 'accuracy': 0.686}
train: {'epoch': 57, 'eta': 19.5664, 'loss': 0.0661, 'lr': 0.0038, 'params': 1359895, 'time_iter': 0.4663, 'accuracy': 1.0}
val: {'epoch': 58, 'loss': 1.0338, 'lr': 0.0036, 'params': 1359895, 'time_iter': 0.3616, 'accuracy': 0.694}
train: {'epoch': 58, 'eta': 19.0996, 'loss': 0.0653, 'lr': 0.0036, 'params': 1359895, 'time_iter': 0.4646, 'accuracy': 1.0}
val: {'epoch': 59, 'loss': 1.0336, 'lr': 0.0035, 'params': 1359895, 'time_iter': 0.3641, 'accuracy': 0.696}
train: {'epoch': 59, 'eta': 18.6339, 'loss': 0.0646, 'lr': 0.0035, 'params': 1359895, 'time_iter': 0.466, 'accuracy': 1.0}
val: {'epoch': 60, 'loss': 1.034, 'lr': 0.0033, 'params': 1359895, 'time_iter': 0.362, 'accuracy': 0.7}
train: {'epoch': 60, 'eta': 18.1668, 'loss': 0.0637, 'lr': 0.0033, 'params': 1359895, 'time_iter': 0.4638, 'accuracy': 1.0}
val: {'epoch': 61, 'loss': 1.0279, 'lr': 0.0032, 'params': 1359895, 'time_iter': 0.3621, 'accuracy': 0.7}
train: {'epoch': 61, 'eta': 17.6993, 'loss': 0.0628, 'lr': 0.0032, 'params': 1359895, 'time_iter': 0.4631, 'accuracy': 1.0}
val: {'epoch': 62, 'loss': 1.0234, 'lr': 0.003, 'params': 1359895, 'time_iter': 0.3624, 'accuracy': 0.704}
train: {'epoch': 62, 'eta': 17.2322, 'loss': 0.0621, 'lr': 0.003, 'params': 1359895, 'time_iter': 0.4635, 'accuracy': 1.0}
val: {'epoch': 63, 'loss': 1.0155, 'lr': 0.0029, 'params': 1359895, 'time_iter': 0.3665, 'accuracy': 0.706}
train: {'epoch': 63, 'eta': 16.7666, 'loss': 0.0615, 'lr': 0.0029, 'params': 1359895, 'time_iter': 0.4661, 'accuracy': 1.0}
val: {'epoch': 64, 'loss': 1.0169, 'lr': 0.0027, 'params': 1359895, 'time_iter': 0.3615, 'accuracy': 0.706}
train: {'epoch': 64, 'eta': 16.3032, 'loss': 0.0609, 'lr': 0.0027, 'params': 1359895, 'time_iter': 0.4701, 'accuracy': 1.0}
val: {'epoch': 65, 'loss': 1.0123, 'lr': 0.0026, 'params': 1359895, 'time_iter': 0.3626, 'accuracy': 0.706}
train: {'epoch': 65, 'eta': 15.8384, 'loss': 0.0603, 'lr': 0.0026, 'params': 1359895, 'time_iter': 0.4678, 'accuracy': 1.0}
val: {'epoch': 66, 'loss': 1.0116, 'lr': 0.0025, 'params': 1359895, 'time_iter': 0.3717, 'accuracy': 0.708}
train: {'epoch': 66, 'eta': 15.3733, 'loss': 0.0597, 'lr': 0.0025, 'params': 1359895, 'time_iter': 0.4674, 'accuracy': 1.0}
val: {'epoch': 67, 'loss': 1.0067, 'lr': 0.0023, 'params': 1359895, 'time_iter': 0.3645, 'accuracy': 0.708}
train: {'epoch': 67, 'eta': 14.9084, 'loss': 0.0591, 'lr': 0.0023, 'params': 1359895, 'time_iter': 0.4679, 'accuracy': 1.0}
val: {'epoch': 68, 'loss': 1.0095, 'lr': 0.0022, 'params': 1359895, 'time_iter': 0.3641, 'accuracy': 0.71}
train: {'epoch': 68, 'eta': 14.445, 'loss': 0.0586, 'lr': 0.0022, 'params': 1359895, 'time_iter': 0.4713, 'accuracy': 1.0}
val: {'epoch': 69, 'loss': 1.0088, 'lr': 0.0021, 'params': 1359895, 'time_iter': 0.3646, 'accuracy': 0.712}
train: {'epoch': 69, 'eta': 13.9793, 'loss': 0.058, 'lr': 0.0021, 'params': 1359895, 'time_iter': 0.4666, 'accuracy': 1.0}
val: {'epoch': 70, 'loss': 0.997, 'lr': 0.0019, 'params': 1359895, 'time_iter': 0.3633, 'accuracy': 0.714}
train: {'epoch': 70, 'eta': 13.5131, 'loss': 0.0574, 'lr': 0.0019, 'params': 1359895, 'time_iter': 0.4654, 'accuracy': 1.0}
val: {'epoch': 71, 'loss': 0.9958, 'lr': 0.0018, 'params': 1359895, 'time_iter': 0.3658, 'accuracy': 0.714}
train: {'epoch': 71, 'eta': 13.0474, 'loss': 0.057, 'lr': 0.0018, 'params': 1359895, 'time_iter': 0.4668, 'accuracy': 1.0}
val: {'epoch': 72, 'loss': 0.9942, 'lr': 0.0017, 'params': 1359895, 'time_iter': 0.3646, 'accuracy': 0.714}
train: {'epoch': 72, 'eta': 12.5824, 'loss': 0.0565, 'lr': 0.0017, 'params': 1359895, 'time_iter': 0.4685, 'accuracy': 1.0}
val: {'epoch': 73, 'loss': 0.9905, 'lr': 0.0016, 'params': 1359895, 'time_iter': 0.3647, 'accuracy': 0.714}
train: {'epoch': 73, 'eta': 12.1165, 'loss': 0.0561, 'lr': 0.0016, 'params': 1359895, 'time_iter': 0.4664, 'accuracy': 1.0}
val: {'epoch': 74, 'loss': 0.9887, 'lr': 0.0015, 'params': 1359895, 'time_iter': 0.3653, 'accuracy': 0.714}
train: {'epoch': 74, 'eta': 11.6509, 'loss': 0.0556, 'lr': 0.0015, 'params': 1359895, 'time_iter': 0.4674, 'accuracy': 1.0}
val: {'epoch': 75, 'loss': 0.9839, 'lr': 0.0014, 'params': 1359895, 'time_iter': 0.3649, 'accuracy': 0.712}
train: {'epoch': 75, 'eta': 11.1853, 'loss': 0.0552, 'lr': 0.0014, 'params': 1359895, 'time_iter': 0.4675, 'accuracy': 1.0}
val: {'epoch': 76, 'loss': 0.9829, 'lr': 0.0012, 'params': 1359895, 'time_iter': 0.3664, 'accuracy': 0.712}
train: {'epoch': 76, 'eta': 10.7201, 'loss': 0.0548, 'lr': 0.0012, 'params': 1359895, 'time_iter': 0.4686, 'accuracy': 1.0}
val: {'epoch': 77, 'loss': 0.9797, 'lr': 0.0011, 'params': 1359895, 'time_iter': 0.3651, 'accuracy': 0.714}
train: {'epoch': 77, 'eta': 10.2542, 'loss': 0.0544, 'lr': 0.0011, 'params': 1359895, 'time_iter': 0.4668, 'accuracy': 1.0}
val: {'epoch': 78, 'loss': 0.9782, 'lr': 0.001, 'params': 1359895, 'time_iter': 0.3652, 'accuracy': 0.712}
train: {'epoch': 78, 'eta': 9.79, 'loss': 0.0541, 'lr': 0.001, 'params': 1359895, 'time_iter': 0.4735, 'accuracy': 1.0}
val: {'epoch': 79, 'loss': 0.9775, 'lr': 0.001, 'params': 1359895, 'time_iter': 0.3648, 'accuracy': 0.71}
train: {'epoch': 79, 'eta': 9.3243, 'loss': 0.0537, 'lr': 0.001, 'params': 1359895, 'time_iter': 0.4679, 'accuracy': 1.0}
val: {'epoch': 80, 'loss': 0.9747, 'lr': 0.0009, 'params': 1359895, 'time_iter': 0.3645, 'accuracy': 0.71}
train: {'epoch': 80, 'eta': 8.8605, 'loss': 0.0534, 'lr': 0.0009, 'params': 1359895, 'time_iter': 0.4767, 'accuracy': 1.0}
val: {'epoch': 81, 'loss': 0.9712, 'lr': 0.0008, 'params': 1359895, 'time_iter': 0.3658, 'accuracy': 0.714}
train: {'epoch': 81, 'eta': 8.3944, 'loss': 0.0531, 'lr': 0.0008, 'params': 1359895, 'time_iter': 0.4676, 'accuracy': 1.0}
val: {'epoch': 82, 'loss': 0.9686, 'lr': 0.0007, 'params': 1359895, 'time_iter': 0.3638, 'accuracy': 0.718}
train: {'epoch': 82, 'eta': 7.9278, 'loss': 0.0528, 'lr': 0.0007, 'params': 1359895, 'time_iter': 0.4651, 'accuracy': 1.0}
val: {'epoch': 83, 'loss': 0.9664, 'lr': 0.0006, 'params': 1359895, 'time_iter': 0.3638, 'accuracy': 0.718}
train: {'epoch': 83, 'eta': 7.4618, 'loss': 0.0526, 'lr': 0.0006, 'params': 1359895, 'time_iter': 0.468, 'accuracy': 1.0}
val: {'epoch': 84, 'loss': 0.9639, 'lr': 0.0005, 'params': 1359895, 'time_iter': 0.3647, 'accuracy': 0.72}
train: {'epoch': 84, 'eta': 6.9952, 'loss': 0.0523, 'lr': 0.0005, 'params': 1359895, 'time_iter': 0.4648, 'accuracy': 1.0}
val: {'epoch': 85, 'loss': 0.9607, 'lr': 0.0005, 'params': 1359895, 'time_iter': 0.3654, 'accuracy': 0.722}
train: {'epoch': 85, 'eta': 6.5294, 'loss': 0.0521, 'lr': 0.0005, 'params': 1359895, 'time_iter': 0.4697, 'accuracy': 1.0}
val: {'epoch': 86, 'loss': 0.9563, 'lr': 0.0004, 'params': 1359895, 'time_iter': 0.3648, 'accuracy': 0.726}
train: {'epoch': 86, 'eta': 6.0632, 'loss': 0.0518, 'lr': 0.0004, 'params': 1359895, 'time_iter': 0.4678, 'accuracy': 1.0}
val: {'epoch': 87, 'loss': 0.9545, 'lr': 0.0004, 'params': 1359895, 'time_iter': 0.3634, 'accuracy': 0.724}
train: {'epoch': 87, 'eta': 5.5967, 'loss': 0.0516, 'lr': 0.0004, 'params': 1359895, 'time_iter': 0.466, 'accuracy': 1.0}
val: {'epoch': 88, 'loss': 0.9523, 'lr': 0.0003, 'params': 1359895, 'time_iter': 0.3635, 'accuracy': 0.724}
train: {'epoch': 88, 'eta': 5.1301, 'loss': 0.0515, 'lr': 0.0003, 'params': 1359895, 'time_iter': 0.4648, 'accuracy': 1.0}
val: {'epoch': 89, 'loss': 0.9502, 'lr': 0.0002, 'params': 1359895, 'time_iter': 0.3652, 'accuracy': 0.728}
train: {'epoch': 89, 'eta': 4.6638, 'loss': 0.0513, 'lr': 0.0002, 'params': 1359895, 'time_iter': 0.4665, 'accuracy': 1.0}
val: {'epoch': 90, 'loss': 0.9484, 'lr': 0.0002, 'params': 1359895, 'time_iter': 0.365, 'accuracy': 0.73}
train: {'epoch': 90, 'eta': 4.1975, 'loss': 0.0512, 'lr': 0.0002, 'params': 1359895, 'time_iter': 0.4674, 'accuracy': 1.0}
val: {'epoch': 91, 'loss': 0.9474, 'lr': 0.0002, 'params': 1359895, 'time_iter': 0.3645, 'accuracy': 0.728}
train: {'epoch': 91, 'eta': 3.7315, 'loss': 0.0511, 'lr': 0.0002, 'params': 1359895, 'time_iter': 0.4706, 'accuracy': 1.0}
val: {'epoch': 92, 'loss': 0.9473, 'lr': 0.0001, 'params': 1359895, 'time_iter': 0.3639, 'accuracy': 0.728}
train: {'epoch': 92, 'eta': 3.2652, 'loss': 0.0509, 'lr': 0.0001, 'params': 1359895, 'time_iter': 0.4687, 'accuracy': 1.0}
val: {'epoch': 93, 'loss': 0.9483, 'lr': 0.0001, 'params': 1359895, 'time_iter': 0.364, 'accuracy': 0.728}
train: {'epoch': 93, 'eta': 2.7988, 'loss': 0.0509, 'lr': 0.0001, 'params': 1359895, 'time_iter': 0.4671, 'accuracy': 1.0}
val: {'epoch': 94, 'loss': 0.9504, 'lr': 0.0001, 'params': 1359895, 'time_iter': 0.3632, 'accuracy': 0.726}
train: {'epoch': 94, 'eta': 2.3326, 'loss': 0.0508, 'lr': 0.0001, 'params': 1359895, 'time_iter': 0.4718, 'accuracy': 1.0}
val: {'epoch': 95, 'loss': 0.9532, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.3646, 'accuracy': 0.724}
train: {'epoch': 95, 'eta': 1.8662, 'loss': 0.0508, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.4681, 'accuracy': 1.0}
val: {'epoch': 96, 'loss': 0.9565, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.3669, 'accuracy': 0.72}
train: {'epoch': 96, 'eta': 1.3995, 'loss': 0.0507, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.4627, 'accuracy': 1.0}
val: {'epoch': 97, 'loss': 0.96, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.3643, 'accuracy': 0.72}
train: {'epoch': 97, 'eta': 0.933, 'loss': 0.0507, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.4653, 'accuracy': 1.0}
val: {'epoch': 98, 'loss': 0.9638, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.3656, 'accuracy': 0.718}
train: {'epoch': 98, 'eta': 0.4665, 'loss': 0.0507, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.4663, 'accuracy': 1.0}
val: {'epoch': 99, 'loss': 0.9676, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.3627, 'accuracy': 0.72}
train: {'epoch': 99, 'eta': 0.0, 'loss': 0.0507, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.4651, 'accuracy': 1.0}
test: {'epoch': 100, 'loss': 0.9459, 'lr': 0.0, 'params': 1359895, 'time_iter': 0.3108, 'accuracy': 0.731}
Results aggregated across runs saved in my_results/Cora_D_05MP/agg
